services:
  # ============================================================================
  # CORE SERVICES
  # ============================================================================
  
  # OpenRouter MCP Server - прокси к LLM
  openrouter-proxy:
    build:
      context: .
      dockerfile: openrouter_proxy/Dockerfile
    container_name: openrouter-proxy
    ports:
      - "8000:8000"
    environment:
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - PORT=8000
      - LOG_LEVEL=INFO
    env_file:
      - .env
    volumes:
      - ./logs:/app/logs
    networks:
      - agent-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ============================================================================
  # AGENTS
  # ============================================================================
  
  # Project Manager - координатор
  project-manager:
    build:
      context: .
      dockerfile: agents/project_manager_agent/Dockerfile
    container_name: project-manager
    ports:
      - "8001:8000"
    environment:
      - OPENROUTER_MCP_URL=http://openrouter-proxy:8000
      - ARCHITECT_URL=http://architect:8000
      - CODE_WRITER_URL=http://code-writer:8000
      - CODE_REVIEWER_URL=http://code-reviewer:8000
      - DOCUMENTATION_URL=http://documentation:8000
      - DEFAULT_MODEL=${DEFAULT_MODEL}
    volumes:
      - ./logs:/app/logs
    networks:
      - agent-network
    restart: unless-stopped
    depends_on:
      openrouter-proxy:
        condition: service_healthy
      architect:
        condition: service_started
      code-writer:
        condition: service_started
      code-reviewer:
        condition: service_started
      documentation:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # Architect Agent - проектирование архитектуры
  architect:
    build:
      context: .
      dockerfile: agents/architect_agent/Dockerfile
    container_name: architect
    ports:
      - "8002:8000"
    environment:
      - OPENROUTER_MCP_URL=http://openrouter-proxy:8000
      - DEFAULT_MODEL=${DEFAULT_MODEL}
    volumes:
      - ./logs:/app/logs
    networks:
      - agent-network
    restart: unless-stopped
    depends_on:
      openrouter-proxy:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Code Writer Agent - написание кода
  code-writer:
    build:
      context: .
      dockerfile: agents/code_writer_agent/Dockerfile
    container_name: code-writer
    ports:
      - "8003:8000"
    environment:
      - OPENROUTER_MCP_URL=http://openrouter-proxy:8000
      - DEFAULT_MODEL=${DEFAULT_MODEL}
    volumes:
      - ./logs:/app/logs
    networks:
      - agent-network
    restart: unless-stopped
    depends_on:
      openrouter-proxy:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Code Reviewer Agent - проверка кода
  code-reviewer:
    build:
      context: .
      dockerfile: agents/code_reviewer_agent/Dockerfile
    container_name: code-reviewer
    ports:
      - "8004:8000"
    environment:
      - OPENROUTER_MCP_URL=http://openrouter-proxy:8000
      - DEFAULT_MODEL=${DEFAULT_MODEL}
    volumes:
      - ./logs:/app/logs
    networks:
      - agent-network
    restart: unless-stopped
    depends_on:
      openrouter-proxy:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Documentation Agent - документация
  documentation:
    build:
      context: .
      dockerfile: agents/documentation_agent/Dockerfile
    container_name: documentation
    ports:
      - "8005:8000"
    environment:
      - OPENROUTER_MCP_URL=http://openrouter-proxy:8000
      - DEFAULT_MODEL=${DEFAULT_MODEL}
    volumes:
      - ./logs:/app/logs
    networks:
      - agent-network
    restart: unless-stopped
    depends_on:
      openrouter-proxy:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================================================
  # ORCHESTRATION
  # ============================================================================
  
  # n8n - workflow automation
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_PROTOCOL=http
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_METRICS=true
      - N8N_LOG_LEVEL=info
      - N8N_USER_MANAGEMENT_DISABLED=true
      - GENERIC_TIMEZONE=Europe/Moscow
      - N8N_DEFAULT_BINARY_DATA_MODE=filesystem
      - EXECUTIONS_TIMEOUT=50000
      - EXECUTIONS_TIMEOUT_MAX=100000
      - N8N_RUNNERS_ENABLED=true
      - N8N_BLOCK_ENV_ACCESS_IN_NODE=false
      - N8N_GIT_NODE_DISABLE_BARE_REPOS=true
      - WEBHOOK_URL=https://tellingly-undaunted-urial.cloudpub.ru:443
    env_file:
      - .env
    volumes:
      - n8n_data:/home/node/.n8n
      - ./n8n_workflows:/home/node/workflows
      - ./logs:/app/logs
    networks:
      - agent-network
    restart: unless-stopped
    depends_on:
      project-manager:
        condition: service_healthy

  # CloudPub - туннель для публикации вебхуков n8n
  cloudpub:
    image: cloudpub/cloudpub:latest
    container_name: cloudpub
    command: ["run"]  # Ключевое исправление - запуск в фоновом режиме
    environment:
      - TOKEN=${CLOUDPUB_TOKEN}
      # HTTP сервис для туннелирования (n8n внутри сети Docker)
      - HTTP=n8n:5678
      - LOG_LEVEL=info
    volumes:
      # Для сохранения состояния туннеля между перезапусками
      - cloudpub_data:/data
    networks:
      - agent-network
    restart: unless-stopped
    depends_on:
      - n8n
    # Добавляем healthcheck для мониторинга состояния туннеля
    healthcheck:
      test: ["CMD", "clo", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    # CloudPub не требует портов, так как создает исходящее соединение

  # ============================================================================
  # MONITORING
  # ============================================================================
  
  # Prometheus - метрики
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yaml:/etc/prometheus/prometheus.yaml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yaml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--web.enable-lifecycle'
    networks:
      - agent-network
    restart: unless-stopped

  # Grafana - дашборды и визуализация метрик
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      # Настройки безопасности и администратора
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      
      # Настройки provisioning для автоматической конфигурации
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_PROVISIONING_ENABLED=true
      
      # Настройки для источников данных
      - GF_DATASOURCES_PROMETHEUS_TYPE=prometheus
      - GF_DATASOURCES_PROMETHEUS_ACCESS=proxy
      - GF_DATASOURCES_PROMETHEUS_URL=http://prometheus:9090
      - GF_DATASOURCES_PROMETHEUS_IS_DEFAULT=true
      
      # Настройки для дашбордов
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/etc/grafana/provisioning/dashboards/multi-agent-dashboard.json
      
      # Настройки логирования
      - GF_LOG_MODE=console
      - GF_LOG_LEVEL=info
      
      # Настройки сервера
      - GF_SERVER_DOMAIN=localhost
      - GF_SERVER_ROOT_URL=http://localhost:3000
    volumes:
      # Хранилище данных Grafana
      - grafana_data:/var/lib/grafana
      
      # Конфигурационные файлы для автоматической настройки источников данных и дашбордов
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      
      # Права доступа к файлам (важно для корректной работы в Docker)
      - ./monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
    networks:
      - agent-network
    restart: unless-stopped
    depends_on:
      - prometheus
    user: "472"  # ID пользователя grafana в официальном образе для корректных прав доступа

# ============================================================================
# NETWORKS & VOLUMES
# ============================================================================

networks:
  agent-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  n8n_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  cloudpub_data:
    driver: local