"""
Project Manager Agent - –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã

–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏:
- –ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç–µ–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
- –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ pipeline –∞–≥–µ–Ω—Ç–æ–≤
- –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤
- –ü–µ—Ä–µ–¥–∞—á–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ review loop (Code Writer ‚Üî Code Reviewer)
- –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è PR
"""
import os
import json
import logging
import uuid
import re
import time
import asyncio
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from contextlib import asynccontextmanager
from enum import Enum

import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
import httpx
from prometheus_client import Counter, Histogram, Gauge, generate_latest

from models import (
    TaskState, AgentType, TaskPriority, FileAction,
    TechStack, FileToCreate, PipelineStep, Pipeline,
    ArchitectureResult, CodeResult, ReviewResult, ReviewIssue,
    DocumentationResult, TaskContext, AgentCallResult,
    WorkflowRequest, WorkflowResponse
)


# ============================================================================
# CONFIGURATION
# ============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# URLs –∞–≥–µ–Ω—Ç–æ–≤
OPENROUTER_MCP_URL = os.getenv("OPENROUTER_MCP_URL", "http://openrouter-mcp:8000")
ARCHITECT_URL = os.getenv("ARCHITECT_URL", "http://architect:8000")
CODE_WRITER_URL = os.getenv("CODE_WRITER_URL", "http://code-writer:8000")
CODE_REVIEWER_URL = os.getenv("CODE_REVIEWER_URL", "http://code-reviewer:8000")
DOCUMENTATION_URL = os.getenv("DOCUMENTATION_URL", "http://documentation:8000")
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL")

# –ú–∞–ø–ø–∏–Ω–≥ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ URLs
AGENT_URLS = {
    AgentType.ARCHITECT: ARCHITECT_URL,
    AgentType.CODE_WRITER: CODE_WRITER_URL,
    AgentType.CODE_REVIEWER: CODE_REVIEWER_URL,
    AgentType.DOCUMENTATION: DOCUMENTATION_URL,
}

# Timeouts
DEFAULT_TIMEOUT = 180  # 3 –º–∏–Ω—É—Ç—ã
LLM_TIMEOUT = 120  # 2 –º–∏–Ω—É—Ç—ã


# ============================================================================
# WORKFLOW STATUS ENUM
# ============================================================================
class WorkflowStatus(str, Enum):
    """–°—Ç–∞—Ç—É—Å—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è workflow"""
    COMPLETED = "completed"      # –í—Å—ë —É—Å–ø–µ—à–Ω–æ
    PARTIAL = "partial"          # –ß–∞—Å—Ç–∏—á–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ (–µ—Å—Ç—å —Ñ–∞–π–ª—ã, –Ω–æ –±—ã–ª–∏ –æ—à–∏–±–∫–∏)
    FAILED = "failed"            # –ü–æ–ª–Ω—ã–π –ø—Ä–æ–≤–∞–ª (–Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞)
    ERROR = "error"              # –°–∏—Å—Ç–µ–º–Ω–∞—è –æ—à–∏–±–∫–∞ (–∏—Å–∫–ª—é—á–µ–Ω–∏–µ)


# ============================================================================
# METRICS
# ============================================================================
TASKS_TOTAL = Counter('pm_tasks_total', 'Total tasks processed', ['status'])
AGENT_CALLS = Counter('pm_agent_calls_total', 'Agent calls', ['agent', 'status'])
REVIEW_ITERATIONS = Histogram('pm_review_iterations', 'Review iterations per task')
TASK_DURATION = Histogram('pm_task_duration_seconds', 'Task duration',
                          buckets=[30, 60, 120, 300, 600, 1200])
ACTIVE_TASKS = Gauge('pm_active_tasks', 'Currently processing tasks')


# ============================================================================
# HTTP CLIENT
# ============================================================================
http_client: Optional[httpx.AsyncClient] = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifecycle manager –¥–ª—è FastAPI"""
    global http_client
    http_client = httpx.AsyncClient(timeout=httpx.Timeout(DEFAULT_TIMEOUT))
    logger.info("HTTP client initialized")
    yield
    await http_client.aclose()
    logger.info("HTTP client closed")


# ============================================================================
# FASTAPI APP
# ============================================================================
app = FastAPI(
    title="Project Manager Agent",
    description="–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
    version="2.0.0",
    lifespan=lifespan
)


# ============================================================================
# LLM HELPER
# ============================================================================
async def call_llm(
    prompt: str,
    system_prompt: Optional[str] = None,
    temperature: float = 0.2
) -> str:
    """–í—ã–∑–æ–≤ LLM —á–µ—Ä–µ–∑ OpenRouter MCP"""
    
    if not system_prompt:
        system_prompt = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ª–∏–¥–µ—Ä –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ü–û.
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∑–∞–¥–∞—á–∏, –ø–ª–∞–Ω–∏—Ä—É–µ—à—å —Ä–∞–±–æ—Ç—É –∫–æ–º–∞–Ω–¥—ã, –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—à—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É.
–í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—à—å –æ—Ç–≤–µ—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –∫–æ–≥–¥–∞ —ç—Ç–æ —É–∫–∞–∑–∞–Ω–æ.
–ü—Ä–∏–Ω–∏–º–∞–µ—à—å —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫."""
    
    try:
        response = await http_client.post(
            f"{OPENROUTER_MCP_URL}/chat/completions",
            json={
                "model": DEFAULT_MODEL,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": temperature
            },
            timeout=LLM_TIMEOUT
        )
        
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"]
        else:
            logger.error(f"LLM error: {response.status_code} - {response.text}")
            return ""
            
    except Exception as e:
        logger.error(f"LLM call failed: {e}")
        return ""


def parse_json_response(response: str) -> Optional[Dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM"""
    try:
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
    except json.JSONDecodeError as e:
        logger.error(f"JSON parse error: {e}")
    return None


# ============================================================================
# TECH STACK ANALYSIS
# ============================================================================
async def analyze_tech_stack(repo_context: Dict[str, Any]) -> TechStack:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
    """
    
    structure = repo_context.get("structure", [])
    key_files = repo_context.get("key_files", {})
    
    # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º —Ñ–∞–π–ª–æ–≤
    extensions = {}
    config_files = []
    
    for item in structure:
        path = item.get("path", "")
        if item.get("type") == "file" and "." in path:
            ext = path.rsplit(".", 1)[-1].lower()
            extensions[ext] = extensions.get(ext, 0) + 1
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        filename = path.split("/")[-1].lower()
        if filename in [
            "package.json", "requirements.txt", "pyproject.toml", "setup.py",
            "cargo.toml", "go.mod", "pom.xml", "build.gradle",
            "composer.json", "gemfile", "mix.exs",
            "dockerfile", "docker-compose.yml", "docker-compose.yaml",
            "tsconfig.json", "webpack.config.js", "vite.config.ts",
            ".eslintrc.js", ".prettierrc", "jest.config.js",
            "makefile", "cmakelists.txt"
        ]:
            config_files.append(path)
    
    prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ –ø—Ä–æ–µ–∫—Ç–∞.

–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º:
{json.dumps(extensions, indent=2)}

–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:
{json.dumps(config_files, indent=2)}

–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤:
{json.dumps(key_files, indent=2, ensure_ascii=False)[:12000]}

–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≤–µ—Ä–Ω–∏ JSON:
{{
    "primary_language": "–æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ (Python/JavaScript/TypeScript/Go/etc)",
    "languages": ["–≤—Å–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —è–∑—ã–∫–∏"],
    "frameworks": ["—Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ (FastAPI/React/Django/Express/etc)"],
    "databases": ["–±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –µ—Å—Ç—å"],
    "tools": ["–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (Docker/Kubernetes/etc)"],
    "package_managers": ["npm/pip/cargo/etc"],
    "testing_frameworks": ["pytest/jest/etc"],
    "ci_cd": ["GitHub Actions/GitLab CI/etc"],
    "architecture_patterns": ["microservices/monolith/MVC/etc"]
}}
"""
    
    response = await call_llm(prompt)
    parsed = parse_json_response(response)
    
    if parsed:
        return TechStack(**parsed)
    
    # Fallback: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º
    lang_map = {
        "py": "Python", "js": "JavaScript", "ts": "TypeScript",
        "go": "Go", "rs": "Rust", "java": "Java", "rb": "Ruby",
        "php": "PHP", "cs": "C#", "cpp": "C++", "c": "C"
    }
    
    primary = "unknown"
    for ext, count in sorted(extensions.items(), key=lambda x: -x[1]):
        if ext in lang_map:
            primary = lang_map[ext]
            break
    
    return TechStack(primary_language=primary, languages=[primary] if primary != "unknown" else [])


# ============================================================================
# PIPELINE PLANNING
# ============================================================================
async def plan_pipeline(context: TaskContext) -> Pipeline:
    """
    –ü–ª–∞–Ω–∏—Ä—É–µ—Ç pipeline –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞—á–∏
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞–∫–∏–µ –∞–≥–µ–Ω—Ç—ã –Ω—É–∂–Ω—ã –∏ –≤ –∫–∞–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
    """
    
    prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–¥–∞—á—É –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –∫–∞–∫–∏–µ –∞–≥–µ–Ω—Ç—ã –Ω—É–∂–Ω—ã –¥–ª—è –µ—ë –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.

–ó–ê–î–ê–ß–ê:
{context.task_description}

–¢–ï–•–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –°–¢–ï–ö:
- –Ø–∑—ã–∫: {context.tech_stack.primary_language if context.tech_stack else 'unknown'}
- –§—Ä–µ–π–º–≤–æ—Ä–∫–∏: {', '.join(context.tech_stack.frameworks) if context.tech_stack else 'unknown'}
- –ü–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(context.tech_stack.architecture_patterns) if context.tech_stack else 'unknown'}

–°–¢–†–£–ö–¢–£–†–ê –†–ï–ü–û–ó–ò–¢–û–†–ò–Ø:
- {len(context.repo_context.get('structure', []))} —Ñ–∞–π–ª–æ–≤
- –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã: {list(context.repo_context.get('key_files', {}).keys())[:20]}

–î–û–°–¢–£–ü–ù–´–ï –ê–ì–ï–ù–¢–´:

1. architect - –ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
   - –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
   - –ü—Ä–æ–µ–∫—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
   - –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã
   - –°–æ–∑–¥–∞—ë—Ç –¥–∏–∞–≥—Ä–∞–º–º—ã
   –ù–£–ñ–ï–ù –µ—Å–ª–∏: –Ω–æ–≤–∞—è —Ñ–∏—á–∞, —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥, –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã

2. code_writer - –ù–∞–ø–∏—Å–∞–Ω–∏–µ –∫–æ–¥–∞
   - –ü–∏—à–µ—Ç –∫–æ–¥ –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ
   - –°–ª–µ–¥—É–µ—Ç —Å—Ç–∏–ª—é –ø—Ä–æ–µ–∫—Ç–∞
   - –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–∏–ø–∏–∑–∞—Ü–∏—é –∏ docstrings
   –ù–£–ñ–ï–ù –¥–ª—è: –ª—é–±—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –∫–æ–¥–∞

3. code_reviewer - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∞
   - –ù–∞—Ö–æ–¥–∏—Ç –±–∞–≥–∏ –∏ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
   - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ
   - –ú–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –∫–æ–¥ –Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É
   –ù–£–ñ–ï–ù: –≤—Å–µ–≥–¥–∞ –ø–æ—Å–ª–µ code_writer

4. documentation - –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
   - –û–±–Ω–æ–≤–ª—è–µ—Ç README
   - –°–æ–∑–¥–∞—ë—Ç API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
   - –ü–∏—à–µ—Ç CHANGELOG
   –ù–£–ñ–ï–ù: –ø–æ—Å–ª–µ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–¥–∞

–ü–†–ê–í–ò–õ–ê PIPELINE:
- architect ‚Üí code_writer (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
- code_writer ‚Üí code_reviewer (–≤—Å–µ–≥–¥–∞)
- code_reviewer –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –Ω–∞ code_writer (review loop)
- documentation –∏–¥—ë—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–º

–í–µ—Ä–Ω–∏ JSON:
{{
    "pipeline": [
        {{
            "agent": "architect",
            "action": "design_architecture",
            "description": "–ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã JWT –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            "input_from": [],
            "priority": "high"
        }},
        {{
            "agent": "code_writer",
            "action": "write_code",
            "description": "–ù–∞–ø–∏—Å–∞–Ω–∏–µ –∫–æ–¥–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            "input_from": ["architect"],
            "priority": "high"
        }},
        {{
            "agent": "code_reviewer",
            "action": "review_code",
            "description": "–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∞",
            "input_from": ["code_writer", "architect"],
            "priority": "high"
        }},
        {{
            "agent": "documentation",
            "action": "write_docs",
            "description": "–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏",
            "input_from": ["code_writer", "code_reviewer"],
            "priority": "medium"
        }}
    ],
    "reasoning": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω —Ç–∞–∫–æ–π pipeline",
    "skip_agents": ["—Å–ø–∏—Å–æ–∫ –∞–≥–µ–Ω—Ç–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã –∏ –ø–æ—á–µ–º—É"]
}}
"""
    
    response = await call_llm(prompt)
    parsed = parse_json_response(response)
    
    if parsed and "pipeline" in parsed:
        steps = []
        for i, step_data in enumerate(parsed["pipeline"]):
            try:
                agent_type = AgentType(step_data["agent"])
                input_from = [AgentType(a) for a in step_data.get("input_from", [])]
                priority = TaskPriority(step_data.get("priority", "medium"))
                
                steps.append(PipelineStep(
                    agent=agent_type,
                    action=step_data.get("action", "process"),
                    description=step_data.get("description", ""),
                    input_from=input_from,
                    priority=priority
                ))
            except (ValueError, KeyError) as e:
                logger.warning(f"Error parsing pipeline step: {e}")
                continue
        
        return Pipeline(
            steps=steps,
            reasoning=parsed.get("reasoning", ""),
            estimated_time_seconds=len(steps) * 60  # ~1 min per step
        )
    
    # Default pipeline
    return Pipeline(
        steps=[
            PipelineStep(
                agent=AgentType.ARCHITECT,
                action="design_architecture",
                description="–ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã",
                input_from=[],
                priority=TaskPriority.HIGH
            ),
            PipelineStep(
                agent=AgentType.CODE_WRITER,
                action="write_code",
                description="–ù–∞–ø–∏—Å–∞–Ω–∏–µ –∫–æ–¥–∞",
                input_from=[AgentType.ARCHITECT],
                priority=TaskPriority.HIGH
            ),
            PipelineStep(
                agent=AgentType.CODE_REVIEWER,
                action="review_code",
                description="–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∞",
                input_from=[AgentType.CODE_WRITER, AgentType.ARCHITECT],
                priority=TaskPriority.HIGH
            ),
            PipelineStep(
                agent=AgentType.DOCUMENTATION,
                action="write_docs",
                description="–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏",
                input_from=[AgentType.CODE_WRITER, AgentType.CODE_REVIEWER],
                priority=TaskPriority.MEDIUM
            )
        ],
        reasoning="Default pipeline for code generation task"
    )


# ============================================================================
# AGENT COMMUNICATION
# ============================================================================
def build_agent_request(
    step: PipelineStep,
    context: TaskContext
) -> Dict[str, Any]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–≥–µ–Ω—Ç–∞ —Å —É—á—ë—Ç–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤
    –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    """
    
    # –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    request = {
        "task": context.task_description,
        "action": step.action,
        "data": {
            "task_id": context.task_id,
            "tech_stack": context.tech_stack.dict() if context.tech_stack else {},
            "repo_context": {
                "structure": context.repo_context.get("structure", [])[:100],
                "key_files": context.repo_context.get("key_files", {})
            }
        },
        "priority": step.priority.value
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
    for source_agent in step.input_from:
        if source_agent == AgentType.ARCHITECT and context.architecture_result:
            # Architect -> –ø–µ—Ä–µ–¥–∞—ë–º –ø–ª–æ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            request["data"]["architecture"] = {
                "components": context.architecture_result.components,
                "patterns": context.architecture_result.patterns,
                "file_structure": context.architecture_result.file_structure,
                "interfaces": context.architecture_result.interfaces,
                "dependencies": context.architecture_result.dependencies,
                "integration_points": context.architecture_result.integration_points,
                "diagrams": context.architecture_result.diagrams,
                "recommendations": context.architecture_result.recommendations
            }
            
        elif source_agent == AgentType.CODE_WRITER and context.code_result:
            # Code Writer -> –ø–µ—Ä–µ–¥–∞—ë–º files –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            request["data"]["code"] = {
                "files": context.code_result.files,
                "implementation_notes": context.code_result.implementation_notes
            }
            
        elif source_agent == AgentType.CODE_REVIEWER and context.review_result:
            # Code Reviewer -> –ø–µ—Ä–µ–¥–∞—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ–≤—å—é
            request["data"]["review"] = {
                "approved": context.review_result.approved,
                "needs_revision": context.review_result.needs_revision,
                "quality_score": context.review_result.quality_score,
                "issues": [i.dict() for i in context.review_result.issues],
                "suggestions": context.review_result.suggestions,
                "summary": context.review_result.summary
            }
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è revise_code
    if step.agent == AgentType.CODE_WRITER and step.action == "revise_code":
        if context.review_result:
            request["data"]["review_comments"] = [i.dict() for i in context.review_result.issues]
            request["data"]["suggestions"] = context.review_result.suggestions
        if context.code_result:
            request["data"]["original_code"] = {
                "files": context.code_result.files
            }
    
    return request


async def call_agent(
    agent: AgentType,
    request: Dict[str, Any],
    timeout: int = DEFAULT_TIMEOUT
) -> AgentCallResult:
    """
    –í—ã–∑—ã–≤–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    """
    
    url = AGENT_URLS.get(agent)
    if not url:
        return AgentCallResult(
            agent=agent,
            status="error",
            duration_seconds=0,
            error=f"Unknown agent: {agent}"
        )
    
    start_time = time.time()
    
    try:
        logger.info(f"Calling {agent.value} at {url}/process")
        
        response = await http_client.post(
            f"{url}/process",
            json=request,
            timeout=timeout
        )
        
        duration = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            AGENT_CALLS.labels(agent=agent.value, status="success").inc()
            
            return AgentCallResult(
                agent=agent,
                status="success",
                duration_seconds=duration,
                result=result
            )
        else:
            error_msg = f"HTTP {response.status_code}: {response.text[:500]}"
            AGENT_CALLS.labels(agent=agent.value, status="error").inc()
            
            return AgentCallResult(
                agent=agent,
                status="error",
                duration_seconds=duration,
                error=error_msg
            )
            
    except httpx.TimeoutException:
        duration = time.time() - start_time
        AGENT_CALLS.labels(agent=agent.value, status="timeout").inc()
        
        return AgentCallResult(
            agent=agent,
            status="timeout",
            duration_seconds=duration,
            error=f"Timeout after {timeout}s"
        )
        
    except Exception as e:
        duration = time.time() - start_time
        AGENT_CALLS.labels(agent=agent.value, status="error").inc()
        
        return AgentCallResult(
            agent=agent,
            status="error",
            duration_seconds=duration,
            error=str(e)
        )


def update_context_with_result(
    context: TaskContext,
    agent: AgentType,
    result: Dict[str, Any]
) -> TaskContext:
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ—Ç –∞–≥–µ–Ω—Ç–∞
    –ò–°–ü–†–ê–í–õ–ï–ù–û: –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    """
    
    if agent == AgentType.ARCHITECT:
        # Architect –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–ª–æ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        context.architecture_result = ArchitectureResult(
            components=result.get("components", []),
            patterns=result.get("patterns", []),
            file_structure=result.get("file_structure", []),
            interfaces=result.get("interfaces", []),
            dependencies=result.get("dependencies", []),
            integration_points=result.get("integration_points", []),
            diagrams=result.get("diagrams", {}),
            recommendations=result.get("recommendations", [])
        )
        
    elif agent == AgentType.CODE_WRITER:
        # Code Writer –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç files –∫–∞–∫ List[CodeFile]
        files_raw = result.get("files", [])
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ dict –µ—Å–ª–∏ —ç—Ç–æ Pydantic –º–æ–¥–µ–ª–∏
        files = []
        for f in files_raw:
            if hasattr(f, 'dict'):
                files.append(f.dict())
            elif isinstance(f, dict):
                files.append(f)
        
        context.code_result = CodeResult(
            files=files,
            implementation_notes=result.get("implementation_notes", []),
            changes_made=result.get("changes_made", []),
            addressed_issues=result.get("addressed_issues", []),
            unaddressed_issues=result.get("unaddressed_issues", [])
        )
        
    elif agent == AgentType.CODE_REVIEWER:
        # Code Reviewer –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç result —Å –≤–ª–æ–∂–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        review_data = result.get("result", result)
        
        issues = []
        for i in review_data.get("issues", []):
            issues.append(ReviewIssue(
                id=i.get("id", str(uuid.uuid4())[:8]),
                type=i.get("type", "unknown"),
                severity=i.get("severity", "medium"),
                title=i.get("title", ""),
                description=i.get("description", ""),
                file_path=i.get("file_path"),
                line_number=i.get("line_number"),
                suggestion=i.get("suggestion"),
                code_snippet=i.get("code_snippet")
            ))
        
        context.review_result = ReviewResult(
            approved=review_data.get("approved", False),
            needs_revision=review_data.get("needs_revision", True),
            quality_score=review_data.get("quality_score", 0),
            issues=issues,
            suggestions=review_data.get("suggestions", []),
            summary=review_data.get("summary", ""),
            metrics=review_data.get("metrics", {}),
            blocking_issues=review_data.get("blocking_issues", [])
        )
        
    elif agent == AgentType.DOCUMENTATION:
        # Documentation –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç files
        files_raw = result.get("files", [])
        
        files = []
        for f in files_raw:
            if f:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º None
                if hasattr(f, 'dict'):
                    files.append(f.dict())
                elif isinstance(f, dict):
                    files.append(f)
        
        context.documentation_result = DocumentationResult(
            files=files,
            sections_created=result.get("sections_created", [])
        )
    
    return context


# ============================================================================
# REVIEW LOOP
# ============================================================================
async def handle_review_loop(context: TaskContext) -> TaskContext:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ü–∏–∫–ª —Ä–µ–≤—å—é: Code Writer ‚Üî Code Reviewer
    –ú–∞–∫—Å–∏–º—É–º max_review_iterations –∏—Ç–µ—Ä–∞—Ü–∏–π
    """
    
    while (context.review_result and 
           context.review_result.needs_revision and
           context.review_iterations < context.max_review_iterations):
        
        context.review_iterations += 1
        context.current_state = TaskState.REVISION
        
        context.log_step(
            "review_loop",
            f"Iteration {context.review_iterations}: sending code back to Code Writer",
            {
                "issues_count": len(context.review_result.issues),
                "critical": len(context.review_result.critical_issues),
                "high": len(context.review_result.high_issues)
            }
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–µ–≤–∏–∑–∏–π
        context.revision_history.append({
            "iteration": context.review_iterations,
            "issues": [i.dict() for i in context.review_result.issues],
            "quality_score": context.review_result.quality_score
        })
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É Code Writer'—É
        revision_step = PipelineStep(
            agent=AgentType.CODE_WRITER,
            action="revise_code",
            description=f"Revision iteration {context.review_iterations}",
            input_from=[AgentType.CODE_REVIEWER, AgentType.ARCHITECT]
        )
        
        revision_request = build_agent_request(revision_step, context)
        revision_result = await call_agent(AgentType.CODE_WRITER, revision_request)
        
        if revision_result.status != "success":
            context.log_error(
                "review_loop",
                f"Code Writer revision failed: {revision_result.error}"
            )
            break
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–æ–≤—ã–º –∫–æ–¥–æ–º
        context = update_context_with_result(
            context, 
            AgentType.CODE_WRITER, 
            revision_result.result
        )
        
        # –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ —Ä–µ–≤—å—é
        context.current_state = TaskState.REVIEWING
        
        review_step = PipelineStep(
            agent=AgentType.CODE_REVIEWER,
            action="review_code",
            description=f"Review after revision {context.review_iterations}",
            input_from=[AgentType.CODE_WRITER, AgentType.ARCHITECT]
        )
        
        review_request = build_agent_request(review_step, context)
        review_result = await call_agent(AgentType.CODE_REVIEWER, review_request)
        
        if review_result.status != "success":
            context.log_error(
                "review_loop",
                f"Code Reviewer failed: {review_result.error}"
            )
            break
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —Ä–µ–≤—å—é
        context = update_context_with_result(
            context,
            AgentType.CODE_REVIEWER,
            review_result.result
        )
        
        context.log_step(
            "review_loop",
            f"Iteration {context.review_iterations} complete",
            {
                "approved": context.review_result.approved,
                "quality_score": context.review_result.quality_score
            }
        )
    
    REVIEW_ITERATIONS.observe(context.review_iterations)
    
    return context


# ============================================================================
# PIPELINE EXECUTION
# ============================================================================
async def execute_pipeline(context: TaskContext) -> Tuple[TaskContext, bool]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç pipeline —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
    
    Returns:
        Tuple[TaskContext, bool]: (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)
    """
    
    if not context.pipeline:
        context.log_error("execute_pipeline", "No pipeline defined")
        context.current_state = TaskState.FAILED
        return context, False
    
    executed_steps = []
    critical_failure = False
    successful_steps = 0
    failed_steps = 0
    
    for i, step in enumerate(context.pipeline.steps):
        context.current_step_index = i
        context.log_step(
            "execute_step",
            f"Starting step {i+1}/{len(context.pipeline.steps)}: {step.agent.value}.{step.action}",
            {"description": step.description}
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        state_map = {
            AgentType.ARCHITECT: TaskState.ARCHITECTURE,
            AgentType.CODE_WRITER: TaskState.CODING,
            AgentType.CODE_REVIEWER: TaskState.REVIEWING,
            AgentType.DOCUMENTATION: TaskState.DOCUMENTING
        }
        context.current_state = state_map.get(step.agent, TaskState.PENDING)
        
        # –°–æ–±–∏—Ä–∞–µ–º –∑–∞–ø—Ä–æ—Å
        request = build_agent_request(step, context)
        
        # –í—ã–∑—ã–≤–∞–µ–º –∞–≥–µ–Ω—Ç–∞
        result = await call_agent(step.agent, request, step.timeout_seconds)
        
        executed_steps.append({
            "step": i + 1,
            "agent": step.agent.value,
            "action": step.action,
            "status": result.status,
            "duration": result.duration_seconds,
            "error": result.error
        })
        
        if result.status != "success":
            # –ü—Ä–æ–±—É–µ–º retry
            if step.retry_count < step.max_retries:
                step.retry_count += 1
                context.log_step("retry", f"Retrying {step.agent.value} (attempt {step.retry_count})")
                result = await call_agent(step.agent, request, step.timeout_seconds)
                executed_steps[-1]["status"] = result.status
                executed_steps[-1]["error"] = result.error
            
            if result.status != "success":
                failed_steps += 1
                context.log_error(
                    "execute_step",
                    f"Step failed: {step.agent.value}",
                    {"error": result.error}
                )
                
                # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: Code Writer –¥–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª—ã
                if step.agent == AgentType.CODE_WRITER:
                    critical_failure = True
                    context.log_error(
                        "critical_failure",
                        "Code Writer failed to generate code - stopping pipeline"
                    )
                    break
                
                continue
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        context = update_context_with_result(context, step.agent, result.result)
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: Code Writer –≤–µ—Ä–Ω—É–ª 0 —Ñ–∞–π–ª–æ–≤
        if step.agent == AgentType.CODE_WRITER:
            if not context.code_result or not context.code_result.files:
                critical_failure = True
                context.log_error(
                    "critical_failure",
                    "Code Writer returned 0 files - stopping pipeline",
                    {"implementation_notes": context.code_result.implementation_notes if context.code_result else []}
                )
                break
            else:
                context.log_step(
                    "execute_step",
                    f"Code Writer created {len(context.code_result.files)} files"
                )
        
        successful_steps += 1
        context.log_step(
            "execute_step",
            f"Step completed: {step.agent.value}",
            {"duration": result.duration_seconds}
        )
        
        # –ü–æ—Å–ª–µ Code Reviewer –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–µ–Ω –ª–∏ review loop
        if step.agent == AgentType.CODE_REVIEWER:
            if context.review_result and context.review_result.needs_revision:
                context = await handle_review_loop(context)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å
    if critical_failure:
        context.current_state = TaskState.FAILED
        context.log_step("execute_pipeline", "Pipeline FAILED due to critical error")
        return context, False
    elif failed_steps > 0:
        # –ï—Å—Ç—å –æ—à–∏–±–∫–∏, –Ω–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ
        if successful_steps > 0:
            context.current_state = TaskState.COMPLETED  # –ß–∞—Å—Ç–∏—á–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ
            context.log_step(
                "execute_pipeline", 
                f"Pipeline completed with errors: {successful_steps} succeeded, {failed_steps} failed"
            )
            return context, True  # –ß–∞—Å—Ç–∏—á–Ω—ã–π —É—Å–ø–µ—Ö
        else:
            context.current_state = TaskState.FAILED
            context.log_step("execute_pipeline", "Pipeline FAILED - all steps failed")
            return context, False
    else:
        context.log_step("execute_pipeline", f"Pipeline completed successfully. Steps executed: {len(executed_steps)}")
        return context, True


# ============================================================================
# STATUS DETERMINATION
# ============================================================================
def determine_workflow_status(
    context: TaskContext,
    pipeline_success: bool,
    has_files: bool
) -> WorkflowStatus:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å workflow –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Args:
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏
        pipeline_success: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è pipeline
        has_files: –ï—Å—Ç—å –ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    
    Returns:
        WorkflowStatus: –°—Ç–∞—Ç—É—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    """
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–π 1: –ï—Å–ª–∏ state = FAILED, —Ç–æ failed
    if context.current_state == TaskState.FAILED:
        return WorkflowStatus.FAILED
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–π 2: –ï—Å–ª–∏ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤–æ–æ–±—â–µ - failed
    if not has_files:
        return WorkflowStatus.FAILED
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–π 3: –ï—Å–ª–∏ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ - failed
    has_critical_errors = any(
        "critical" in str(e).lower() or "critical_failure" in str(e.get("step", "")).lower()
        for e in context.errors
    )
    if has_critical_errors:
        return WorkflowStatus.FAILED
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–π 4: –ï—Å–ª–∏ pipeline –Ω–µ —É—Å–ø–µ—à–µ–Ω, –Ω–æ –µ—Å—Ç—å —Ñ–∞–π–ª—ã - partial
    if not pipeline_success and has_files:
        return WorkflowStatus.PARTIAL
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–π 5: –ï—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏, –Ω–æ pipeline —É—Å–ø–µ—à–µ–Ω - partial
    if context.errors and has_files:
        return WorkflowStatus.PARTIAL
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–π 6: –ï—Å–ª–∏ —Ä–µ–≤—å—é –Ω–µ –ø—Ä–æ—à–ª–æ - partial
    if context.review_result and not context.review_result.approved:
        # –ù–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª—ã, –≤—Å—ë —Ä–∞–≤–Ω–æ partial, –∞ –Ω–µ failed
        if has_files:
            return WorkflowStatus.PARTIAL
        return WorkflowStatus.FAILED
    
    # –í—Å—ë —Ö–æ—Ä–æ—à–æ
    return WorkflowStatus.COMPLETED


# ============================================================================
# METADATA GENERATION
# ============================================================================
async def generate_branch_name(context: TaskContext) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–º—è –≤–µ—Ç–∫–∏"""
    
    prompt = f"""
–°–æ–∑–¥–∞–π –∏–º—è git –≤–µ—Ç–∫–∏ –¥–ª—è –∑–∞–¥–∞—á–∏.

–ó–∞–¥–∞—á–∞: {context.task_description[:200]}
–°—Ç–µ–∫: {context.tech_stack.primary_language if context.tech_stack else 'unknown'}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –¢–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –¥–µ—Ñ–∏—Å—ã
- –ú–∞–∫—Å–∏–º—É–º 50 —Å–∏–º–≤–æ–ª–æ–≤
- –§–æ—Ä–º–∞—Ç: feature/–∫—Ä–∞—Ç–∫–æ–µ-–æ–ø–∏—Å–∞–Ω–∏–µ –∏–ª–∏ fix/–∫—Ä–∞—Ç–∫–æ–µ-–æ–ø–∏—Å–∞–Ω–∏–µ

–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –∏–º—è –≤–µ—Ç–∫–∏ –±–µ–∑ –∫–∞–≤—ã—á–µ–∫ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π.
"""
    
    response = await call_llm(prompt, temperature=0.1)
    branch = re.sub(r'[^a-zA-Z0-9\-/]', '-', response.strip()[:50])
    branch = re.sub(r'-+', '-', branch).strip('-')
    
    if not branch or len(branch) < 5:
        import uuid
        branch = f"feature/task-{uuid.uuid4().hex[:8]}"
    
    return branch


async def generate_commit_message(context: TaskContext) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç commit message"""
    
    files_info = []
    all_files = context.get_all_files()
    for f in all_files[:10]:
        files_info.append(f"{f.action.value}: {f.path}")
    
    prompt = f"""
–°–æ–∑–¥–∞–π commit message –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏–π.

–ó–∞–¥–∞—á–∞: {context.task_description[:200]}

–§–∞–π–ª—ã:
{chr(10).join(files_info)}

–§–æ—Ä–º–∞—Ç: type(scope): description

–¢–∏–ø—ã: feat, fix, docs, refactor, test, chore

–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ commit message –±–µ–∑ –∫–∞–≤—ã—á–µ–∫.
"""
    
    response = await call_llm(prompt, temperature=0.1)
    message = response.strip().strip('"').strip("'")
    
    if not message or len(message) < 10:
        message = f"feat: implement {context.task_description[:40]}"
    
    return message[:72]  # Git —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –¥–æ 72 —Å–∏–º–≤–æ–ª–æ–≤


async def generate_pr_metadata(context: TaskContext) -> Tuple[str, str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ PR"""
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
    files_created = len([f for f in context.get_all_files() if f.action == FileAction.CREATE])
    files_updated = len([f for f in context.get_all_files() if f.action == FileAction.UPDATE])
    
    arch_summary = ""
    if context.architecture_result:
        arch_summary = f"""
### üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {len(context.architecture_result.components)}
- –ü–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(context.architecture_result.patterns[:5])}
"""
    
    review_summary = ""
    if context.review_result:
        review_summary = f"""
### üîç –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ–≤—å—é
- –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞: {context.review_result.quality_score}/10
- –ò—Ç–µ—Ä–∞—Ü–∏–π —Ä–µ–≤—å—é: {context.review_iterations}
- –°—Ç–∞—Ç—É—Å: {'‚úÖ Approved' if context.review_result.approved else '‚ö†Ô∏è Needs attention'}
"""
    
    prompt = f"""
–°–æ–∑–¥–∞–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ Pull Request.

–ó–∞–¥–∞—á–∞:
{context.task_description}

–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
- –§–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {files_created}
- –§–∞–π–ª–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {files_updated}
- –ò—Ç–µ—Ä–∞—Ü–∏–π —Ä–µ–≤—å—é: {context.review_iterations}

–§–∞–π–ª—ã:
{chr(10).join([f.path for f in context.get_all_files()[:15]])}

–í–µ—Ä–Ω–∏ JSON:
{{
    "title": "–ö—Ä–∞—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–¥–æ 72 —Å–∏–º–≤–æ–ª–æ–≤)",
    "description": "–ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ Markdown —Å —Å–µ–∫—Ü–∏—è–º–∏: –û–ø–∏—Å–∞–Ω–∏–µ, –ò–∑–º–µ–Ω–µ–Ω–∏—è, –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
}}
"""
    
    response = await call_llm(prompt)
    parsed = parse_json_response(response)
    
    if parsed:
        title = parsed.get("title", f"Feature: {context.task_description[:50]}")
        description = parsed.get("description", "")
    else:
        title = f"Feature: {context.task_description[:50]}"
        description = f"## –û–ø–∏—Å–∞–Ω–∏–µ\n\n{context.task_description}"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–µ–∫—Ü–∏–∏
    description += f"""

---
## üìä –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ

- **Task ID**: `{context.task_id}`
- **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏**: {context.tech_stack.primary_language if context.tech_stack else 'N/A'}
- **–§–∞–π–ª–æ–≤**: {files_created} —Å–æ–∑–¥–∞–Ω–æ, {files_updated} –æ–±–Ω–æ–≤–ª–µ–Ω–æ
{arch_summary}
{review_summary}

### üìù Pipeline –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
"""
    
    for log in context.reasoning_log[-10:]:
        description += f"- {log['step']}: {log['message']}\n"
    
    return title, description


async def generate_summary(context: TaskContext, status: WorkflowStatus) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –¥–ª—è Telegram"""
    
    all_files = context.get_all_files()
    
    # –≠–º–æ–¥–∑–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç–∞—Ç—É—Å–∞
    status_emoji_map = {
        WorkflowStatus.COMPLETED: "‚úÖ",
        WorkflowStatus.PARTIAL: "‚ö†Ô∏è",
        WorkflowStatus.FAILED: "‚ùå",
        WorkflowStatus.ERROR: "üí•"
    }
    status_emoji = status_emoji_map.get(status, "‚ùì")
    
    status_text_map = {
        WorkflowStatus.COMPLETED: "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞!",
        WorkflowStatus.PARTIAL: "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —á–∞—Å—Ç–∏—á–Ω–æ",
        WorkflowStatus.FAILED: "–ó–∞–¥–∞—á–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞",
        WorkflowStatus.ERROR: "–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"
    }
    status_text = status_text_map.get(status, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å")
    
    summary = f"""{status_emoji} {status_text}

üìã {context.task_description[:100]}{'...' if len(context.task_description) > 100 else ''}

üîß –°—Ç–µ–∫: {context.tech_stack.primary_language if context.tech_stack else 'N/A'}
üì¶ –§—Ä–µ–π–º–≤–æ—Ä–∫–∏: {', '.join((context.tech_stack.frameworks or [])[:3]) if context.tech_stack else 'N/A'}

üåø –í–µ—Ç–∫–∞: {context.branch_name or 'N/A'}
üìù –§–∞–π–ª–æ–≤: {len(all_files)}
üîÑ –†–µ–≤—å—é –∏—Ç–µ—Ä–∞—Ü–∏–π: {context.review_iterations}
"""
    
    if context.review_result:
        summary += f"‚≠ê –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞: {context.review_result.quality_score}/10\n"
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
    if context.errors:
        summary += f"\n‚ö†Ô∏è –û—à–∏–±–æ–∫: {len(context.errors)}\n"
        for err in context.errors[:3]:
            summary += f"  - {err.get('step', 'unknown')}: {err.get('message', 'unknown error')[:50]}\n"
    
    if all_files:
        summary += "\nüìÅ –§–∞–π–ª—ã:"
        for f in all_files[:5]:
            icon = "+" if f.action == FileAction.CREATE else "~"
            summary += f"\n  {icon} {f.path}"
        
        if len(all_files) > 5:
            summary += f"\n  ... –∏ –µ—â—ë {len(all_files) - 5}"
    else:
        summary += "\nüìÅ –§–∞–π–ª–æ–≤ –Ω–µ —Å–æ–∑–¥–∞–Ω–æ"
    
    return summary


# ============================================================================
# MAIN WORKFLOW ENDPOINT
# ============================================================================
@app.post("/workflow/process", response_model=WorkflowResponse)
async def process_workflow(request: WorkflowRequest):
    """
    –û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏
    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
    """
    
    start_time = time.time()
    ACTIVE_TASKS.inc()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ - –≤—ã–Ω–æ—Å–∏–º –Ω–∞—Ä—É–∂—É –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –≤ except
    context = None
    pipeline_success = False
    
    try:
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context = TaskContext(
            task_description=request.task_description,
            repo_owner=request.repo_owner,
            repo_name=request.repo_name,
            base_branch=request.base_branch,
            repo_context=request.repo_context or {},
            max_review_iterations=request.max_review_iterations
        )
        
        context.current_state = TaskState.PLANNING
        context.log_step("init", f"Task received: {request.task_description[:100]}")
        
        logger.info(f"[{context.task_id[:8]}] Starting workflow")
        
        # 2. –ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç–µ–∫–∞
        context.log_step("analyze_stack", "Analyzing tech stack...")
        try:
            context.tech_stack = await analyze_tech_stack(context.repo_context)
            context.log_step(
                "analyze_stack",
                f"Stack: {context.tech_stack.primary_language}, "
                f"frameworks: {context.tech_stack.frameworks}"
            )
        except Exception as e:
            context.log_error("analyze_stack", f"Failed to analyze tech stack: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º —Å—Ç–µ–∫–æ–º
            context.tech_stack = TechStack(primary_language="unknown")
        
        # 3. –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ pipeline
        context.log_step("plan_pipeline", "Planning execution pipeline...")
        try:
            context.pipeline = await plan_pipeline(context)
            context.log_step(
                "plan_pipeline",
                f"Pipeline: {' ‚Üí '.join([s.agent.value for s in context.pipeline.steps])}",
                {"reasoning": context.pipeline.reasoning}
            )
        except Exception as e:
            context.log_error("plan_pipeline", f"Failed to plan pipeline: {e}")
            raise  # –ë–µ–∑ pipeline –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –Ω–µ–ª—å–∑—è
        
        # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ –≤–µ—Ç–∫–∏
        try:
            context.branch_name = await generate_branch_name(context)
            context.log_step("generate_branch", f"Branch: {context.branch_name}")
        except Exception as e:
            context.log_error("generate_branch", f"Failed to generate branch name: {e}")
            context.branch_name = f"feature/task-{context.task_id[:8]}"
        
        # 5. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ pipeline
        context.log_step("execute_pipeline", "Starting pipeline execution...")
        context, pipeline_success = await execute_pipeline(context)
        
        # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤
        all_files = context.get_all_files()
        has_files = len(all_files) > 0
        
        # 7. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        workflow_status = determine_workflow_status(context, pipeline_success, has_files)
        
        # 8. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª—ã)
        if has_files:
            context.current_state = TaskState.AGGREGATING
            
            try:
                context.commit_message = await generate_commit_message(context)
            except Exception as e:
                context.log_error("generate_commit", f"Failed: {e}")
                context.commit_message = f"feat: implement task {context.task_id[:8]}"
            
            try:
                context.pr_title, context.pr_description = await generate_pr_metadata(context)
            except Exception as e:
                context.log_error("generate_pr", f"Failed: {e}")
                context.pr_title = f"Task: {context.task_description[:50]}"
                context.pr_description = context.task_description
        else:
            context.commit_message = ""
            context.pr_title = ""
            context.pr_description = ""
        
        # 9. –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π state
        if workflow_status == WorkflowStatus.COMPLETED:
            context.current_state = TaskState.COMPLETED
        elif workflow_status == WorkflowStatus.PARTIAL:
            context.current_state = TaskState.COMPLETED  # Partial —Ç–æ–∂–µ considered "done"
        else:
            context.current_state = TaskState.FAILED
        
        # 10. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è summary
        summary = await generate_summary(context, workflow_status)
        
        duration = time.time() - start_time
        TASK_DURATION.observe(duration)
        TASKS_TOTAL.labels(status=workflow_status.value).inc()
        
        context.log_step(
            "completed",
            f"Workflow finished with status: {workflow_status.value} in {duration:.1f}s",
            {"files_count": len(all_files), "errors_count": len(context.errors)}
        )
        
        logger.info(f"[{context.task_id[:8]}] Workflow {workflow_status.value} in {duration:.1f}s")
        
        # 11. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        return WorkflowResponse(
            task_id=context.task_id,
            status=workflow_status.value,
            tech_stack=context.tech_stack,
            branch_name=context.branch_name,
            files_to_create=[f.dict() for f in all_files],
            commit_message=context.commit_message,
            pr_title=context.pr_title,
            pr_description=context.pr_description,
            summary=summary,
            pipeline_executed=[
                {"agent": s.agent.value, "action": s.action}
                for s in context.pipeline.steps
            ] if context.pipeline else [],
            agent_results={
                "architect": context.architecture_result.dict() if context.architecture_result else None,
                "code_writer": context.code_result.dict() if context.code_result else None,
                "code_reviewer": context.review_result.dict() if context.review_result else None,
                "documentation": context.documentation_result.dict() if context.documentation_result else None
            },
            review_iterations=context.review_iterations,
            reasoning_log=context.reasoning_log,
            errors=context.errors,
            total_duration_seconds=duration
        )
        
    except HTTPException:
        raise
        
    except Exception as e:
        logger.exception(f"Workflow error: {e}")
        
        duration = time.time() - start_time
        TASKS_TOTAL.labels(status="error").inc()
        
        # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –±—ã–ª —Å–æ–∑–¥–∞–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∞—Å—Ç–∏—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if context:
            context.log_error("fatal", f"Unhandled exception: {str(e)}")
            context.current_state = TaskState.FAILED
            
            return WorkflowResponse(
                task_id=context.task_id,
                status=WorkflowStatus.ERROR.value,
                tech_stack=context.tech_stack,
                branch_name=context.branch_name or "",
                files_to_create=[],
                commit_message="",
                pr_title="",
                pr_description="",
                summary=f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)[:200]}",
                pipeline_executed=[],
                agent_results={},
                review_iterations=0,
                reasoning_log=context.reasoning_log,
                errors=context.errors + [{"step": "fatal", "message": str(e)}],
                total_duration_seconds=duration
            )
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Å–æ–∑–¥–∞–Ω - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
        raise HTTPException(
            status_code=500,
            detail={
                "error": str(e),
                "status": "error"
            }
        )
    
    finally:
        ACTIVE_TASKS.dec()


# ============================================================================
# ADDITIONAL ENDPOINTS
# ============================================================================
@app.get("/health")
async def health_check():
    """Health check endpoint"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤
    agents_status = {}
    for agent, url in AGENT_URLS.items():
        try:
            response = await http_client.get(f"{url}/health", timeout=5)
            agents_status[agent.value] = response.status_code == 200
        except:
            agents_status[agent.value] = False
    
    return {
        "status": "healthy",
        "service": "project_manager",
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat(),
        "agents": agents_status
    }


@app.get("/metrics")
async def metrics():
    """Prometheus metrics endpoint"""
    return generate_latest()


@app.get("/")
async def root():
    """Root endpoint —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–µ—Ä–≤–∏—Å–µ"""
    return {
        "service": "Project Manager Agent",
        "version": "2.0.0",
        "description": "–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
        "responsibilities": [
            "–ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç–µ–∫–∞",
            "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ pipeline –∞–≥–µ–Ω—Ç–æ–≤",
            "–ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
            "–ü–µ—Ä–µ–¥–∞—á–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏",
            "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ review loop",
            "–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
        ],
        "does_not": [
            "–ü–∏—Å–∞—Ç—å –∫–æ–¥",
            "–î–µ–ª–∞—Ç—å —Ä–µ–≤—å—é –∫–æ–¥–∞",
            "–°–æ–∑–¥–∞–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é",
            "–ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É"
        ],
        "statuses": {
            "completed": "–í—Å—ë —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ",
            "partial": "–ß–∞—Å—Ç–∏—á–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ (–µ—Å—Ç—å —Ñ–∞–π–ª—ã, –Ω–æ –±—ã–ª–∏ –æ—à–∏–±–∫–∏)",
            "failed": "–ü—Ä–æ–≤–∞–ª (–Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞)",
            "error": "–°–∏—Å—Ç–µ–º–Ω–∞—è –æ—à–∏–±–∫–∞ (–∏—Å–∫–ª—é—á–µ–Ω–∏–µ)"
        },
        "endpoints": {
            "workflow": "POST /workflow/process",
            "health": "GET /health",
            "metrics": "GET /metrics"
        },
        "connected_agents": list(AGENT_URLS.keys())
    }


# ============================================================================
# MAIN
# ============================================================================
if __name__ == "__main__":
    uvicorn.run(
        "server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )